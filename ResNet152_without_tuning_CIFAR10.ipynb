{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152_without_tuning_CIFAR10",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsvenky89/Assignemnt_2_ML/blob/master/ResNet152_without_tuning_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uEGs3SNl-LX-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RPEMOuNu-aga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reset_tf_session():\n",
        "    K.clear_session()\n",
        "    tf.reset_default_graph()\n",
        "    s = K.get_session()\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TRsksUd9dBxr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import stuff"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-29T18:51:38.014629Z",
          "start_time": "2017-10-29T18:51:37.876670Z"
        },
        "id": "99DOO0FadBxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "sys.setrecursionlimit(3000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFZg0VpcdBxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !!! remember to clear session/graph if you rebuild your graph to avoid out-of-memory errors !!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-29T18:51:58.907479Z",
          "start_time": "2017-10-29T18:51:42.206537Z"
        },
        "scrolled": true,
        "id": "J4oQid8-dBx2",
        "colab_type": "code",
        "outputId": "d64186e3-73b1-485a-dd6d-a9d299e8ea39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"TensoreFlow Ver:\",tf.__version__)\n",
        "print(\"Keras Ver:\",keras.__version__)\n",
        "import keras.utils\n",
        "from keras_tqdm import TQDMCallback\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensoreFlow Ver: 1.12.0\n",
            "Keras Ver: 2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2AIqhGyMdBx4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fill in your Coursera token and email\n",
        "To successfully submit your answers to our grader, please fill in your Coursera submission token and email"
      ]
    },
    {
      "metadata": {
        "id": "KeoFK7VPdByI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T23:44:40.870302Z",
          "start_time": "2017-09-03T23:44:39.221603Z"
        },
        "id": "w12haDrsdByJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train_i, y_train_i), (x_test_i, y_test_i) = cifar10.load_data()\n",
        "x_train = x_train_i[range(2000),:]\n",
        "y_train = y_train_i[range(2000),:]\n",
        "x_test = x_test_i[range(1000),:]\n",
        "y_test = y_test_i[range(1000),:]\n",
        "del x_train_i,y_train_i,x_test_i,y_test_i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-04T00:27:41.648291Z",
          "start_time": "2017-09-04T00:27:41.644322Z"
        },
        "id": "nlpjSPgSdByN",
        "colab_type": "code",
        "outputId": "6003fe6a-91a9-488e-e740-0c1556b9babf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
        "print(\"Test samples:\", x_test.shape, y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples: (2000, 32, 32, 3) (2000, 1)\n",
            "Test samples: (1000, 32, 32, 3) (1000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T23:44:41.009639Z",
          "start_time": "2017-09-03T23:44:40.877013Z"
        },
        "id": "G5Xbbxf2dByR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
        "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-03T23:44:42.285830Z",
          "start_time": "2017-09-03T23:44:41.011216Z"
        },
        "id": "7yej1PvkdByT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show random images from train\n",
        "cols = 8\n",
        "rows = 2\n",
        "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
        "for i in range(cols):\n",
        "    for j in range(rows):\n",
        "        random_index = np.random.randint(0, len(y_train))\n",
        "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
        "        ax.grid('off')\n",
        "        ax.axis('off')\n",
        "        ax.imshow(x_train[random_index, :])\n",
        "        ax.set_title(cifar10_classes[y_train[random_index, 0]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sqe4UeSMdByW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "GlGQM5q50JIh",
        "colab_type": "code",
        "outputId": "499c76f4-eca4-410d-c709-dd51fa24ea68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#resizing the data to match the input size of ResNet 152 Architecture\n",
        "x_train_r = []\n",
        "x_test_r = []\n",
        "for i in range(2000):\n",
        " x_train_r.append(cv2.resize(x_train[i,:,:,:],(224,224)))\n",
        "x_train_res= np.array(x_train_r,dtype=np.uint8)\n",
        "for i in range(1000):\n",
        " x_test_r.append(cv2.resize(x_test[i,:,:,:],(224,224)))\n",
        "x_test_res = np.array(x_test_r,dtype=np.uint8)\n",
        "del x_train_r\n",
        "del x_test_r\n",
        "print(x_train_res.shape,y_train.shape)\n",
        "print(x_test_res.shape,y_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 224, 224, 3) (2000, 1)\n",
            "(1000, 224, 224, 3) (1000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gbt6vqS6dByX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to normalize inputs like this: $$x_{norm} = \\frac{x}{255} - 0.5$$\n",
        "\n",
        "We need to convert class labels to one-hot encoded vectors. Use __keras.utils.to_categorical__."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-09-04T00:25:55.504781Z",
          "start_time": "2017-09-04T00:25:55.500823Z"
        },
        "id": "ghvVlISndByX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs\n",
        "x_train2 = x_train_res/255. - 0.5\n",
        "x_test2 = x_test_res/255. - 0.5\n",
        "del x_train_res\n",
        "del x_test_res\n",
        "# convert class labels to one-hot encoded, should have shape (?, NUM_CLASSES)\n",
        "y_train2 = keras.utils.to_categorical(y_train[range(2000),:], num_classes=NUM_CLASSES)\n",
        "y_test2 = keras.utils.to_categorical(y_test[range(1000),:], num_classes=NUM_CLASSES)\n",
        "print(x_test2[600,:,:,:])\n",
        "print(y_train2.shape,y_test2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UsX_sVgIdBya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define CNN architecture"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T11:39:23.631230Z",
          "start_time": "2017-08-24T11:39:23.627975Z"
        },
        "id": "GY2cKFtidByb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import necessary building blocks\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Flatten, Activation, add\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import initializers\n",
        "from keras.engine import Layer, InputSpec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T11:39:23.739649Z",
          "start_time": "2017-08-24T11:39:23.632558Z"
        },
        "id": "CZUSgTV8dByg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Scale(Layer):\n",
        "    '''Custom Layer for ResNet used for BatchNormalization.\n",
        "    \n",
        "    Learns a set of weights and biases used for scaling the input data.\n",
        "    the output consists simply in an element-wise multiplication of the input\n",
        "    and a sum of a set of constants:\n",
        "        out = in * gamma + beta,\n",
        "    where 'gamma' and 'beta' are the weights and biases larned.\n",
        "    # Arguments\n",
        "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
        "            if your input tensor has shape (samples, channels, rows, cols),\n",
        "            set axis to 1 to normalize per feature map (channels axis).\n",
        "        momentum: momentum in the computation of the\n",
        "            exponential average of the mean and standard deviation\n",
        "            of the data, for feature-wise normalization.\n",
        "        weights: Initialization weights.\n",
        "            List of 2 Numpy arrays, with shapes:\n",
        "            `[(input_shape,), (input_shape,)]`\n",
        "        beta_init: name of initialization function for shift parameter\n",
        "            (see [initializers](../initializers.md)), or alternatively,\n",
        "            Theano/TensorFlow function to use for weights initialization.\n",
        "            This parameter is only relevant if you don't pass a `weights` argument.\n",
        "        gamma_init: name of initialization function for scale parameter (see\n",
        "            [initializers](../initializers.md)), or alternatively,\n",
        "            Theano/TensorFlow function to use for weights initialization.\n",
        "            This parameter is only relevant if you don't pass a `weights` argument.\n",
        "    '''\n",
        "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
        "        self.momentum = momentum\n",
        "        self.axis = axis\n",
        "        self.beta_init = initializers.get(beta_init)\n",
        "        self.gamma_init = initializers.get(gamma_init)\n",
        "        self.initial_weights = weights\n",
        "        super(Scale, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        shape = (int(input_shape[self.axis]),)\n",
        "\n",
        "        self.gamma = K.variable(self.gamma_init(shape), name='%s_gamma'%self.name)\n",
        "        self.beta = K.variable(self.beta_init(shape), name='%s_beta'%self.name)\n",
        "        self.trainable_weights = [self.gamma, self.beta]\n",
        "\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
        "        base_config = super(Scale, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    '''The identity_block is the block that has no conv layer at shortcut\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
        "\n",
        "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
        "    x = Conv2D(nb_filter2, (kernel_size, kernel_size), name=conv_name_base + '2b', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
        "\n",
        "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
        "\n",
        "    x = add([x, input_tensor], name='res' + str(stage) + block)\n",
        "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    '''conv_block is the block that has a conv layer at shortcut\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
        "    And the shortcut should have subsample=(2,2) as well\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
        "\n",
        "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
        "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),\n",
        "                      name=conv_name_base + '2b', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
        "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
        "\n",
        "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,\n",
        "                             name=conv_name_base + '1', use_bias=False)(input_tensor)\n",
        "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
        "\n",
        "    x = add([x, shortcut], name='res' + str(stage) + block)\n",
        "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
        "    return x\n",
        "  \n",
        "def resnet152_model(weights_path=None):\n",
        "    '''Instantiate the ResNet152 architecture,\n",
        "    # Arguments\n",
        "        weights_path: path to pretrained weight file\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "\n",
        "    # Handle Dimension Ordering for different backends\n",
        "    global bn_axis\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "        img_input = Input(shape=(224,224, 3), name='data')\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "        img_input = Input(shape=(3, 224, 224), name='data')\n",
        "            \n",
        "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
        "    x = Activation('relu', name='conv1_relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    for i in range(1,8):\n",
        "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    for i in range(1,36):\n",
        "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "    x_fc = Flatten()(x_fc)\n",
        "    x_fc = Dense(10, activation='softmax', name='fc10')(x_fc)\n",
        "    #x_fc = tf.dtypes.cast(x_fc,dtype=tf.float32)\n",
        "    model = Model(img_input, x_fc)\n",
        "    \n",
        "    # load weights\n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "     \n",
        "    return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T11:39:23.948546Z",
          "start_time": "2017-08-24T11:39:23.741012Z"
        },
        "id": "ruTGDCrHdByj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# describe model\n",
        "reset_tf_session() # clear default graph\n",
        "weights_path = 'resnet152_weights_tf.h5'\n",
        "model = resnet152_model(weights_path)\n",
        "model.summary()\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # this is our cross-entropy\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']  # report accuracy during training\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTA3585H_W_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# and now we can fit the model with model.fit()\n",
        "# and we don't have to write loops and batching manually as in TensorFlow\n",
        "\n",
        "#model.fit(\n",
        " #   x_train2, \n",
        "  #  y_train2,\n",
        "   # batch_size=200, \n",
        "    #epochs=10,\n",
        "    #validation_data=(x_test2, y_test2),\n",
        "    #callbacks=[TQDMCallback()],\n",
        "    #verbose = 1\n",
        "#)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vFVepKMECL9",
        "colab_type": "code",
        "outputId": "047b6ff7-b998-4936-f6ed-6cad202c42aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(x_test2)\n",
        "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
        "y_pred_test_max_probas = np.max(y_pred_test, axis=1)\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_test_classes))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Z02yc7vdByv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fit model"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:39.059726Z",
          "start_time": "2017-08-24T11:39:23.949926Z"
        },
        "id": "GTEb_fsYdByy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-3  # initial learning rate\n",
        "EPOCH_STEP = 8\n",
        "EPOCHS = 10\n",
        "\n",
        "model.fit(x_train2, y_train2,\n",
        "              steps_per_epoch = 1,\n",
        "              epochs=EPOCHS,\n",
        "              shuffle=True,\n",
        "              verbose=1,\n",
        "              validation_data = (x_test2,y_test2), validation_steps = 1\n",
        "             \n",
        "               )\n",
        "# scheduler of learning rate (decay with epochs)\n",
        "def lr_scheduler(epoch):\n",
        "    return INIT_LR * 0.9 ** epoch\n",
        "\n",
        "# callback for printing of actual learning rate used by optimizer\n",
        "class LrHistory(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        print(\"Learning rate:\", K.get_value(model.optimizer.lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U6lmJFTjdBy1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training takes approximately **1.5 hours**. You're aiming for ~0.80 validation accuracy."
      ]
    },
    {
      "metadata": {
        "id": "ha_kA2RfdBy3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we will save model checkpoints to continue training in case of kernel death\n",
        "model_filename = 'cifar.{0:03d}.hdf5'\n",
        "last_finished_epoch = None\n",
        "\n",
        "#### uncomment below to continue training from model checkpoint\n",
        "#### fill `last_finished_epoch` with your latest finished epoch\n",
        "# from keras.models import load_model\n",
        "# s = reset_tf_session()\n",
        "# last_finished_epoch = 7\n",
        "# model = load_model(model_filename.format(last_finished_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:39.059726Z",
          "start_time": "2017-08-24T11:39:23.949926Z"
        },
        "scrolled": false,
        "id": "ZuhOQvOEdBy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(x_test2,batch_size=BATCH_SIZE,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:39.103672Z",
          "start_time": "2017-08-24T12:18:39.061508Z"
        },
        "id": "9TrH-dejdBy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save weights to file\n",
        "model.save_weights(\"weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:39.298255Z",
          "start_time": "2017-08-24T12:18:39.105314Z"
        },
        "id": "dsjEMw_BdBzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load weights from file (can call without model.fit)\n",
        "model.load_weights(\"weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQI5WTiBdBzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:53.381943Z",
          "start_time": "2017-08-24T12:18:39.299830Z"
        },
        "id": "vuKVKWpLdBzS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# make test predictions\n",
        "y_pred_test = model.predict_proba(x_test2)\n",
        "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
        "y_pred_test_max_probas = np.max(y_pred_test, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:54.293970Z",
          "start_time": "2017-08-24T12:18:53.383809Z"
        },
        "id": "22Gz5SC2dBzV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# confusion matrix and accuracy\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.title('Confusion matrix', fontsize=16)\n",
        "plt.imshow(confusion_matrix(y_test, y_pred_test_classes))\n",
        "plt.xticks(np.arange(10), cifar10_classes, rotation=45, fontsize=12)\n",
        "plt.yticks(np.arange(10), cifar10_classes, fontsize=12)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_test_classes))\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_test_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20ijc7AEdBzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Accuracy on validation data\n",
        "grader.set_answer(\"nQOsg\", accuracy_score(y_test, y_pred_test_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rIGuqIe9dBzb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T12:18:55.568152Z",
          "start_time": "2017-08-24T12:18:54.295958Z"
        },
        "id": "Py5il6fmdBzc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# inspect preditions\n",
        "cols = 8\n",
        "rows = 2\n",
        "fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
        "for i in range(cols):\n",
        "    for j in range(rows):\n",
        "        random_index = np.random.randint(0, len(y_test))\n",
        "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
        "        ax.grid('off')\n",
        "        ax.axis('off')\n",
        "        ax.imshow(x_test[random_index, :])\n",
        "        pred_label = cifar10_classes[y_pred_test_classes[random_index]]\n",
        "        pred_proba = y_pred_test_max_probas[random_index]\n",
        "        true_label = cifar10_classes[y_test[random_index, 0]]\n",
        "        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
        "               pred_label, pred_proba, true_label\n",
        "        ))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T13:23:59.462081Z",
          "start_time": "2017-08-24T13:23:58.896876Z"
        },
        "id": "ccoGL1Z5dBzh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s = reset_tf_session()  # clear default graph\n",
        "K.set_learning_phase(0)  # disable dropout\n",
        "model = make_model()\n",
        "model.load_weights(\"weights.h5\")  # that were saved after model.fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-08-24T13:24:00.360163Z",
          "start_time": "2017-08-24T13:24:00.351539Z"
        },
        "id": "sOflwhTNdBzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# all weights we have\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}